{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3kveNdvJnr1"
      },
      "outputs": [],
      "source": [
        "!pip install pandas replicate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import json # Akan digunakan untuk memproses output JSON dari Granite\n",
        "from google.colab import userdata\n",
        "from replicate import Client\n",
        "# Set the API token\n",
        "api_token = userdata.get('REPLICATE_AI')\n",
        "replicate_client = Client(api_token=api_token)\n",
        "\n",
        "print(\"Lingkungan Google Colab siap!\")\n",
        "\n",
        "pd.read_csv('Womens Clothing E-Commerce Reviews.csv')\n"
      ],
      "metadata": {
        "id": "wKLemzbTKCUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df=pd.read_csv('Womens Clothing E-Commerce Reviews.csv')\n",
        "\n",
        "print(\"Informasi Dataset Awal:\")\n",
        "print(df.info())\n",
        "print(\"\\n5 baris pertama:\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "LYGivRjDWetr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Langkah-langkah pembersihan data dasar:\n",
        "# - Hapus baris yang memiliki nilai kosong pada kolom 'Review Text'\n",
        "df.dropna(subset=['Review Text'], inplace=True)\n",
        "\n",
        "# - Hapus kolom yang tidak relevan untuk analisis sentimen, untuk menghemat memori\n",
        "df.drop(columns=['Unnamed: 0', 'Title'], inplace=True)\n",
        "\n",
        "# - Pastikan kolom 'Review Text' bertipe string\n",
        "df['Review Text'] = df['Review Text'].astype(str)\n",
        "\n",
        "print(\"\\nInformasi Dataset Setelah Pembersihan:\")\n",
        "print(df.info())\n",
        "print(f\"\\nJumlah ulasan yang akan dianalisis: {len(df)}\")\n"
      ],
      "metadata": {
        "id": "ndiMxcsHWwsB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat fungsi untuk memanggil model Granite\n",
        "import json # Import json here\n",
        "\n",
        "def analyze_review_with_granite(review_text):\n",
        "    \"\"\"\n",
        "    Fungsi ini mengambil teks ulasan dan mengirimkannya ke model IBM Granite\n",
        "    untuk analisis sentimen, ekstraksi topik, dan ringkasan.\n",
        "    Fungsi ini secara spesifik meminta output dalam format JSON.\n",
        "    \"\"\"\n",
        "\n",
        "# Membuat prompt yang terstruktur dan rinci\n",
        "    prompt_template = f\"\"\"\n",
        "    Anda adalah seorang analis data yang bertugas menganalisis ulasan produk e-commerce.\n",
        "    Lakukan analisis terhadap ulasan berikut dan berikan hasilnya dalam format JSON.\n",
        "\n",
        "    Tugas Anda:\n",
        "    1.  Klasifikasikan sentimen keseluruhan dari ulasan sebagai salah satu dari: \"Positif\", \"Negatif\", atau \"Campuran\".\n",
        "    2.  Identifikasi dan ekstrak topik atau area fokus utama yang dibahas. Setiap topik harus diklasifikasikan sebagai \"Positif\" atau \"Negatif\" sesuai sentimennya. Contoh topik: \"kualitas bahan\", \"ukuran\", \"harga\", \"pengiriman\".\n",
        "    3.  Tulis ringkasan singkat dari ulasan yang mencakup poin-poin terpenting.\n",
        "\n",
        "    Ulasan Pelanggan:\n",
        "    {review_text}\n",
        "\n",
        "    Format Output JSON yang Diharapkan:\n",
        "    {{\n",
        "      \"sentimen_keseluruhan\": \"...\",\n",
        "      \"area_fokus\": [\n",
        "        {{\"topik\": \"...\", \"sentimen\": \"...\"}}\n",
        "      ],\n",
        "      \"ringkasan\": \"...\"\n",
        "    }}\n",
        "    \"\"\"\n",
        "\n",
        "    # Konfigurasi parameter model yang dioptimalkan\n",
        "    # Kita menggunakan parameter yang lebih seimbang untuk hasil yang lebih baik\n",
        "    parameters = {\n",
        "        \"max_tokens\": 1024, # Nilai yang cukup besar untuk output lengkap\n",
        "        \"temperature\": 0.5, # Membuat output lebih faktual dan stabil\n",
        "        \"top_p\": 0.9,      # Mempertahankan variasi kata tanpa terlalu melenceng\n",
        "        \"repetition_penalty\": 1.1, # Menghindari pengulangan kata\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        print(f\"Menganalisis ulasan: {review_text[:50]}...\")\n",
        "        # Ensure replicate_client is defined globally or in a parent scope\n",
        "        output_generator = replicate_client.run(\n",
        "            \"ibm-granite/granite-3.2-8b-instruct\",\n",
        "            input={\"prompt\": prompt_template, **parameters}\n",
        "        )\n",
        "\n",
        "        full_output = \"\".join(output_generator)\n",
        "\n",
        "        # Penanganan kesalahan JSON yang lebih baik\n",
        "        # Kadang model menghasilkan karakter tambahan (misalnya, `json)\n",
        "        # Kita akan membersihkannya untuk memastikan dapat diurai.\n",
        "        cleaned_output = full_output.strip().replace('```json', '').replace('```', '')\n",
        "        json_output = json.loads(cleaned_output)\n",
        "        return json_output\n",
        "\n",
        "    except json.JSONDecodeError:\n",
        "        print(\"Model gagal memberikan output JSON yang valid. Mengembalikan output mentah.\")\n",
        "        # Attempt to return raw output if JSON decoding fails\n",
        "        return {\"error\": \"Invalid JSON output\", \"raw_output\": full_output if 'full_output' in locals() else \"No output generated\"}\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Terjadi kesalahan saat memanggil model: {e}\")\n",
        "        return {\"error\": str(e)}"
      ],
      "metadata": {
        "id": "JRpezZicWw_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ambil ulasan pertama dari data yang sudah kita bersihkan\n",
        "# Pastikan Anda sudah menjalankan kode untuk memuat data sebelumnya\n",
        "import json # Import json here\n",
        "import pandas as pd # Make sure pandas is imported if not already\n",
        "\n",
        "try:\n",
        "    # Assuming df is already loaded and cleaned from previous cells\n",
        "    # If not, uncomment the following lines:\n",
        "    # df = pd.read_csv('Womens Clothing E-Commerce Reviews.csv')\n",
        "    # df.dropna(subset=['Review Text'], inplace=True)\n",
        "\n",
        "    # Ensure df is available from previous execution\n",
        "    if 'df' not in locals() and 'df' not in globals():\n",
        "        print(\"DataFrame 'df' not found. Please run the data loading and cleaning cells first.\")\n",
        "    else:\n",
        "        sample_review = df['Review Text'].iloc[0]\n",
        "\n",
        "        # Memanggil fungsi analisis kita\n",
        "        # Make sure analyze_review_with_granite is defined in a previous cell and that cell has been run\n",
        "        analysis_result = analyze_review_with_granite(sample_review)\n",
        "        print(\"\\n\\nHasil Analisis Ulasan:\")\n",
        "        print(json.dumps(analysis_result, indent=2))\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"File data tidak ditemukan. Pastikan Anda sudah mengunggah 'Womens Clothing E-Commerce Reviews.csv' ke Colab.\")\n",
        "except IndexError:\n",
        "    print(\"DataFrame kosong atau 'Review Text' column is missing after cleaning. Pastikan file CSV memiliki data yang valid dan pembersihan berjalan dengan benar.\")\n",
        "except NameError as ne:\n",
        "    print(f\"NameError: {ne}. Make sure analyze_review_with_granite function and replicate_client are defined and accessible.\")\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred: {e}\")"
      ],
      "metadata": {
        "id": "Gqk9AlavWxb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengambil sampel acak dari 100 ulasan dari DataFrame yang sudah dibersihkan\n",
        "# Kita menggunakan random_state untuk memastikan sampel yang sama setiap kali kode dijalankan\n",
        "sampled_reviews = df.sample(n=100, random_state=42)\n",
        "\n",
        "print(f\"Berhasil mengambil {len(sampled_reviews)} ulasan sebagai sampel untuk analisis.\")"
      ],
      "metadata": {
        "id": "Q7svspy_Uxxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# List kosong untuk menyimpan hasil analisis dari AI\n",
        "analysis_results = []\n",
        "\n",
        "# Loop untuk memproses setiap ulasan dalam sampel\n",
        "for index, row in sampled_reviews.iterrows():\n",
        "    review_text = row['Review Text']\n",
        "\n",
        "    # Memanggil fungsi analisis dan menambahkan hasilnya ke list\n",
        "    result = analyze_review_with_granite(review_text)\n",
        "\n",
        "    # Menyimpan ulasan asli dan hasil analisis AI\n",
        "    result['original_review'] = review_text\n",
        "    analysis_results.append(result)\n",
        "\n",
        "    # Jeda singkat untuk menghindari batasan API (rate limiting)\n",
        "    time.sleep(2)\n",
        "\n",
        "print(\"\\nProses analisis batch selesai!\")"
      ],
      "metadata": {
        "id": "81iJ5BByU_aY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# List kosong untuk menyimpan hasil analisis dari AI\n",
        "analysis_results = []\n",
        "\n",
        "# Loop untuk memproses setiap ulasan dalam sampel\n",
        "for index, row in sampled_reviews.iterrows():\n",
        "    review_text = row['Review Text']\n",
        "\n",
        "    # Tambahkan retry logic untuk mengatasi rate limiting\n",
        "    max_retries = 5\n",
        "    retry_count = 0\n",
        "    success = False\n",
        "\n",
        "    while not success and retry_count < max_retries:\n",
        "        try:\n",
        "            # Memanggil fungsi analisis dan menambahkan hasilnya ke list\n",
        "            print(f\"Menganalisis ulasan: {review_text[:50]}...\")\n",
        "            result = analyze_review_with_granite(review_text)\n",
        "\n",
        "            # Jika berhasil, tandai sebagai sukses dan keluar dari loop\n",
        "            result['original_review'] = review_text\n",
        "            analysis_results.append(result)\n",
        "            success = True\n",
        "\n",
        "        except Exception as e:\n",
        "            if \"status: 429\" in str(e):\n",
        "                # Ekstrak waktu tunggu dari pesan error (contoh: \"~7s\")\n",
        "                try:\n",
        "                    wait_time = int(''.join(filter(str.isdigit, str(e))))\n",
        "                    print(f\"Rate limited. Menunggu {wait_time} detik dan mencoba lagi...\")\n",
        "                    time.sleep(wait_time + 1) # Tambahkan 1 detik untuk amannya\n",
        "                except (ValueError, IndexError):\n",
        "                    # Jika tidak bisa mengekstrak waktu, tunggu 10 detik\n",
        "                    print(\"Rate limited. Tidak dapat mengekstrak waktu tunggu. Menunggu 10 detik...\")\n",
        "                    time.sleep(10)\n",
        "                retry_count += 1\n",
        "            else:\n",
        "                print(f\"Terjadi kesalahan lain: {e}. Mengabaikan ulasan ini.\")\n",
        "                analysis_results.append({\"error\": str(e), \"original_review\": review_text})\n",
        "                success = True # Lanjut ke ulasan berikutnya meskipun ada error\n",
        "\n",
        "# Setelah loop, buat DataFrame dari hasil\n",
        "results_df = pd.DataFrame(analysis_results)\n",
        "\n",
        "print(\"\\nProses analisis batch selesai!\")\n",
        "\n",
        "# Menampilkan 5 baris pertama dari DataFrame baru\n",
        "print(\"\\nDataFrame Hasil Analisis AI:\")\n",
        "print(results_df.head())\n",
        "\n",
        "# Menampilkan informasi tentang DataFrame baru\n",
        "print(results_df.info())"
      ],
      "metadata": {
        "id": "SjYmH6MJXs3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import pandas as pd # Pastikan pandas diimpor jika belum\n",
        "import json # Pastikan json diimpor jika belum\n",
        "\n",
        "# ====================================================================\n",
        "# Tahap 4: Analisis Ulasan Skala Besar dengan Perbaikan\n",
        "# ====================================================================\n",
        "\n",
        "# List kosong untuk menyimpan hasil analisis dari AI\n",
        "analysis_results = []\n",
        "\n",
        "# Mengambil sampel acak dari 100 ulasan dari DataFrame yang sudah dibersihkan\n",
        "# Kita menggunakan random_state untuk memastikan sampel yang sama setiap kali kode dijalankan\n",
        "sampled_reviews = df.sample(n=100, random_state=42)\n",
        "print(f\"Berhasil mengambil {len(sampled_reviews)} ulasan sebagai sampel untuk analisis.\")\n",
        "\n",
        "# Loop untuk memproses setiap ulasan dalam sampel\n",
        "for index, row in sampled_reviews.iterrows():\n",
        "    review_text = row['Review Text']\n",
        "\n",
        "    # Menambahkan retry logic untuk mengatasi rate limiting\n",
        "    max_retries = 5\n",
        "    retry_count = 0\n",
        "    success = False\n",
        "\n",
        "    while not success and retry_count < max_retries:\n",
        "        try:\n",
        "            print(f\"Menganalisis ulasan: {review_text[:50]}... (Percobaan ke-{retry_count + 1})\")\n",
        "\n",
        "            # Memanggil fungsi analisis kita\n",
        "            result = analyze_review_with_granite(review_text)\n",
        "\n",
        "            # Jika berhasil, tandai sebagai sukses dan keluar dari loop\n",
        "            result['original_review'] = review_text\n",
        "            analysis_results.append(result)\n",
        "            success = True\n",
        "\n",
        "        except Exception as e:\n",
        "            if \"status: 429\" in str(e):\n",
        "                try:\n",
        "                    # Mencoba mengekstrak waktu tunggu dari pesan error\n",
        "                    wait_time = int(''.join(filter(str.isdigit, str(e))))\n",
        "                    # Tambahkan jeda waktu yang disarankan + sedikit ekstra\n",
        "                    print(f\"Rate limited. Menunggu {wait_time + 1} detik dan mencoba lagi...\")\n",
        "                    time.sleep(wait_time + 1)\n",
        "                except (ValueError, IndexError):\n",
        "                    # Jika gagal, jeda dengan aman selama 10 detik\n",
        "                    print(\"Rate limited. Tidak dapat mengekstrak waktu tunggu. Menunggu 10 detik...\")\n",
        "                    time.sleep(10)\n",
        "                retry_count += 1\n",
        "            else:\n",
        "                print(f\"Terjadi kesalahan lain: {e}. Mengabaikan ulasan ini.\")\n",
        "                analysis_results.append({\"error\": str(e), \"original_review\": review_text})\n",
        "                success = True\n",
        "\n",
        "    # Jeda yang lebih panjang dan konsisten antar permintaan\n",
        "    print(\"Menunggu 10 detik sebelum permintaan berikutnya...\")\n",
        "    time.sleep(10)\n",
        "\n",
        "\n",
        "# ====================================================================\n",
        "# Tahap 5: Pembuatan dan Analisis DataFrame Hasil\n",
        "# ====================================================================\n",
        "\n",
        "# Membuat DataFrame dari list hasil analisis\n",
        "results_df = pd.DataFrame(analysis_results)\n",
        "\n",
        "# Menampilkan 5 baris pertama dari DataFrame baru\n",
        "print(\"\\nProses analisis batch selesai!\")\n",
        "print(\"\\nDataFrame Hasil Analisis AI:\")\n",
        "display(results_df.head())\n",
        "\n",
        "# Menampilkan informasi tentang DataFrame baru\n",
        "print(\"\\nInformasi DataFrame Hasil:\")\n",
        "display(results_df.info())"
      ],
      "metadata": {
        "id": "2CpOUPgFZZlI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import pandas as pd # Pastikan pandas diimpor jika belum\n",
        "import json # Pastikan json diimpor jika belum\n",
        "\n",
        "# ====================================================================\n",
        "# Tahap 4: Analisis Ulasan Skala Besar dengan Perbaikan Akhir\n",
        "# ====================================================================\n",
        "\n",
        "# List kosong untuk menyimpan hasil analisis dari AI\n",
        "analysis_results = []\n",
        "\n",
        "# Mengambil sampel acak dari 100 ulasan dari DataFrame yang sudah dibersihkan\n",
        "# Kita menggunakan random_state untuk memastikan sampel yang sama setiap kali kode dijalankan\n",
        "sampled_reviews = df.sample(n=100, random_state=42)\n",
        "print(f\"Berhasil mengambil {len(sampled_reviews)} ulasan sebagai sampel untuk analisis.\")\n",
        "\n",
        "# Loop untuk memproses setiap ulasan dalam sampel\n",
        "for index, review_text in sampled_reviews['Review Text'].items():\n",
        "\n",
        "    # Menambahkan retry logic untuk mengatasi rate limiting dan error lainnya\n",
        "    max_retries = 5\n",
        "    retry_count = 0\n",
        "    success = False\n",
        "\n",
        "    while not success and retry_count < max_retries:\n",
        "        try:\n",
        "            print(f\"Menganalisis ulasan: {review_text[:50]}... (Percobaan ke-{retry_count + 1})\")\n",
        "\n",
        "            # Memanggil fungsi analisis kita\n",
        "            result = analyze_review_with_granite(review_text)\n",
        "\n",
        "            # Jika berhasil, tambahkan ulasan asli dan tandai sukses\n",
        "            result['original_review'] = review_text\n",
        "            analysis_results.append(result)\n",
        "            success = True\n",
        "\n",
        "        except Exception as e:\n",
        "            if \"status: 429\" in str(e):\n",
        "                try:\n",
        "                    # Mencoba mengekstrak waktu tunggu dari pesan error\n",
        "                    wait_time = int(''.join(filter(str.isdigit, str(e))))\n",
        "                    print(f\"Rate limited. Menunggu {wait_time + 2} detik dan mencoba lagi...\")\n",
        "                    time.sleep(wait_time + 2) # Tambahkan 2 detik untuk amannya\n",
        "                except (ValueError, IndexError):\n",
        "                    print(\"Rate limited. Tidak dapat mengekstrak waktu tunggu. Menunggu 15 detik...\")\n",
        "                    time.sleep(15)\n",
        "                retry_count += 1\n",
        "            else:\n",
        "                print(f\"Terjadi kesalahan: {e}. Mencatat error dan melanjutkan...\")\n",
        "                analysis_results.append({\"error\": str(e), \"original_review\": review_text})\n",
        "                success = True\n",
        "\n",
        "    # Jeda yang lebih panjang dan konsisten antar permintaan untuk mencegah throttling\n",
        "    if success:\n",
        "        print(\"Analisis berhasil. Menunggu 10 detik sebelum permintaan berikutnya...\")\n",
        "        time.sleep(10)\n",
        "\n",
        "\n",
        "# ====================================================================\n",
        "# Tahap 5: Pembuatan dan Analisis DataFrame Hasil\n",
        "# ====================================================================\n",
        "\n",
        "# Membuat DataFrame dari list hasil analisis\n",
        "results_df = pd.DataFrame(analysis_results)\n",
        "\n",
        "# Menampilkan 5 baris pertama dari DataFrame baru\n",
        "print(\"\\nProses analisis batch selesai!\")\n",
        "print(\"\\nDataFrame Hasil Analisis AI:\")\n",
        "display(results_df.head())\n",
        "\n",
        "# Menampilkan informasi tentang DataFrame baru\n",
        "print(\"\\nInformasi DataFrame Hasil:\")\n",
        "display(results_df.info())"
      ],
      "metadata": {
        "id": "lEHrADg3j5z-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================================\n",
        "# Tahap 4: Analisis Ulasan Skala Besar dengan Perbaikan Akhir\n",
        "# ====================================================================\n",
        "\n",
        "# List kosong untuk menyimpan hasil analisis dari AI\n",
        "analysis_results = []\n",
        "\n",
        "# Mengambil sampel acak dari 100 ulasan dari DataFrame yang sudah dibersihkan\n",
        "# Kita menggunakan random_state untuk memastikan sampel yang sama setiap kali kode dijalankan\n",
        "sampled_reviews = df.sample(n=100, random_state=42)\n",
        "print(f\"Berhasil mengambil {len(sampled_reviews)} ulasan sebagai sampel untuk analisis.\")\n",
        "\n",
        "# Loop untuk memproses setiap ulasan dalam sampel\n",
        "for index, review_text in sampled_reviews['Review Text'].items():\n",
        "\n",
        "    # Menambahkan retry logic untuk mengatasi rate limiting dan error lainnya\n",
        "    max_retries = 5\n",
        "    retry_count = 0\n",
        "    success = False\n",
        "\n",
        "    while not success and retry_count < max_retries:\n",
        "        try:\n",
        "            print(f\"Menganalisis ulasan: {review_text[:50]}... (Percobaan ke-{retry_count + 1})\")\n",
        "\n",
        "            # Memanggil fungsi analisis kita\n",
        "            result = analyze_review_with_granite(review_text)\n",
        "\n",
        "            # Jika berhasil, tambahkan ulasan asli dan tandai sukses\n",
        "            result['original_review'] = review_text\n",
        "            analysis_results.append(result)\n",
        "            success = True\n",
        "\n",
        "        except Exception as e:\n",
        "            if \"status: 429\" in str(e):\n",
        "                try:\n",
        "                    # Mencoba mengekstrak waktu tunggu dari pesan error\n",
        "                    wait_time = int(''.join(filter(str.isdigit, str(e))))\n",
        "                    print(f\"Rate limited. Menunggu {wait_time + 2} detik dan mencoba lagi...\")\n",
        "                    time.sleep(wait_time + 2) # Tambahkan 2 detik untuk amannya\n",
        "                except (ValueError, IndexError):\n",
        "                    print(\"Rate limited. Tidak dapat mengekstrak waktu tunggu. Menunggu 15 detik...\")\n",
        "                    time.sleep(15)\n",
        "                retry_count += 1\n",
        "            else:\n",
        "                print(f\"Terjadi kesalahan: {e}. Mencatat error dan melanjutkan...\")\n",
        "                analysis_results.append({\"error\": str(e), \"original_review\": review_text})\n",
        "                success = True\n",
        "\n",
        "    # Jeda yang lebih panjang dan konsisten antar permintaan untuk mencegah throttling\n",
        "    if success:\n",
        "        print(\"Analisis berhasil. Menunggu 10 detik sebelum permintaan berikutnya...\")\n",
        "        time.sleep(10)\n",
        "\n",
        "\n",
        "# ====================================================================\n",
        "# Tahap 5: Pembuatan dan Analisis DataFrame Hasil\n",
        "# ====================================================================\n",
        "\n",
        "# Membuat DataFrame dari list hasil analisis\n",
        "results_df = pd.DataFrame(analysis_results)\n",
        "\n",
        "# Menampilkan 5 baris pertama dari DataFrame baru\n",
        "print(\"\\nProses analisis batch selesai!\")\n",
        "print(\"\\nDataFrame Hasil Analisis AI:\")\n",
        "display(results_df.head())\n",
        "\n",
        "# Menampilkan informasi tentang DataFrame baru\n",
        "print(\"\\nInformasi DataFrame Hasil:\")\n",
        "display(results_df.info())\n",
        "\n"
      ],
      "metadata": {
        "id": "4IoMPJyarbFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================================\n",
        "# Tahap 6: Pasca-Pemrosesan Hasil Analisis\n",
        "# ====================================================================\n",
        "\n",
        "# Menemukan ulasan yang gagal dianalisis\n",
        "failed_reviews = results_df[results_df['error'] == 'Invalid JSON output']\n",
        "\n",
        "# Loop untuk memperbaiki ulasan yang gagal\n",
        "for index, row in failed_reviews.iterrows():\n",
        "    raw_output = row['raw_output']\n",
        "    original_review = row['original_review']\n",
        "\n",
        "    try:\n",
        "        # Mencoba memperbaiki output mentah menjadi JSON yang valid\n",
        "        # Di sini, kita asumsikan output mentah adalah JSON yang rusak\n",
        "        # Kami akan mencoba memuatnya sebagai JSON dan menanganinya\n",
        "        fixed_json = json.loads(raw_output)\n",
        "\n",
        "        # Mengisi kembali kolom di DataFrame dengan data yang diperbaiki\n",
        "        results_df.loc[index, 'sentimen_keseluruhan'] = fixed_json.get('sentimen_keseluruhan')\n",
        "        results_df.loc[index, 'area_fokus'] = fixed_json.get('area_fokus')\n",
        "        results_df.loc[index, 'ringkasan'] = fixed_json.get('ringkasan')\n",
        "        results_df.loc[index, 'error'] = None # Hapus error setelah diperbaiki\n",
        "\n",
        "    except json.JSONDecodeError:\n",
        "        # Jika perbaikan JSON gagal, kita bisa mencoba pendekatan lain\n",
        "        print(f\"Gagal memperbaiki ulasan: {original_review[:50]}...\")\n",
        "        # Kita bisa membiarkan ulasan ini sebagai \"error\" atau mencoba prompt ulang\n",
        "        # Untuk saat ini, kita biarkan saja agar tidak memakan waktu lama\n",
        "\n",
        "# Menampilkan informasi DataFrame setelah perbaikan\n",
        "print(\"\\nDataFrame setelah perbaikan:\")\n",
        "print(results_df.info())"
      ],
      "metadata": {
        "id": "ibRH_zENyxB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================================\n",
        "# Tahap 7: Pembersihan Akhir Data\n",
        "# ====================================================================\n",
        "\n",
        "# Menghapus kolom 'error' dan 'raw_output' karena tidak diperlukan untuk analisis lebih lanjut\n",
        "results_df_clean = results_df.drop(columns=['error', 'raw_output'])\n",
        "\n",
        "# Menghapus baris yang memiliki nilai NaN di kolom sentimen\n",
        "# Ini akan membuat DataFrame kita bersih dan siap untuk analisis\n",
        "results_df_clean.dropna(subset=['sentimen_keseluruhan'], inplace=True)\n",
        "\n",
        "print(\"DataFrame final setelah pembersihan:\")\n",
        "display(results_df_clean.head())\n",
        "display(results_df_clean.info())\n"
      ],
      "metadata": {
        "id": "ZRxYKFfczJrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set the style for the plots\n",
        "sns.set_style('whitegrid')\n",
        "\n",
        "# Create a bar plot for the overall sentiment\n",
        "plt.figure(figsize=(8, 6))\n",
        "sentiment_counts = results_df_clean['sentimen_keseluruhan'].value_counts()\n",
        "sns.barplot(x=sentiment_counts.index, y=sentiment_counts.values, palette='viridis')\n",
        "plt.title('Distribusi Sentimen Keseluruhan Ulasan (Sampel 88)', fontsize=16)\n",
        "plt.xlabel('Sentimen', fontsize=12)\n",
        "plt.ylabel('Jumlah Ulasan', fontsize=12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "b6evrT3E3M_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import ast\n",
        "\n",
        "# Extract all focus areas from the 'area_fokus' column\n",
        "all_topics = []\n",
        "for topics_list in results_df_clean['area_fokus']:\n",
        "    # Use ast.literal_eval to safely convert the string representation of a list into a list\n",
        "    if isinstance(topics_list, str):\n",
        "        topics_list = ast.literal_eval(topics_list)\n",
        "\n",
        "    for topic_dict in topics_list:\n",
        "        all_topics.append(topic_dict['topik'])\n",
        "\n",
        "# Count the occurrences of each topic\n",
        "topic_counts = Counter(all_topics)\n",
        "most_common_topics = topic_counts.most_common(10) # Get the top 10 topics\n",
        "\n",
        "# Create a DataFrame for easy plotting\n",
        "topics_df = pd.DataFrame(most_common_topics, columns=['Topik', 'Jumlah'])\n",
        "\n",
        "# Create a bar plot for the most common topics\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.barplot(x='Jumlah', y='Topik', data=topics_df, palette='magma')\n",
        "plt.title('10 Topik yang Paling Sering Dibahas', fontsize=16)\n",
        "plt.xlabel('Jumlah Pembahasan', fontsize=12)\n",
        "plt.ylabel('Topik', fontsize=12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "s-Qp2mF_32Ru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new DataFrame to hold sentiment counts for each topic\n",
        "topic_sentiment_df = []\n",
        "for topics_list in results_df_clean['area_fokus']:\n",
        "    if isinstance(topics_list, str):\n",
        "        topics_list = ast.literal_eval(topics_list)\n",
        "\n",
        "    for topic_dict in topics_list:\n",
        "        topic_sentiment_df.append({\n",
        "            'topik': topic_dict['topik'],\n",
        "            'sentimen': topic_dict['sentimen']\n",
        "        })\n",
        "\n",
        "topic_sentiment_df = pd.DataFrame(topic_sentiment_df)\n",
        "\n",
        "# Filter for the top 5 most common topics for clarity\n",
        "top_5_topics = [topic for topic, count in topic_counts.most_common(5)]\n",
        "filtered_topic_df = topic_sentiment_df[topic_sentiment_df['topik'].isin(top_5_topics)]\n",
        "\n",
        "# Create a grouped bar chart\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.countplot(y='topik', hue='sentimen', data=filtered_topic_df, palette='tab10')\n",
        "plt.title('Sentimen Berdasarkan Topik (Top 5)', fontsize=16)\n",
        "plt.xlabel('Jumlah Ulasan', fontsize=12)\n",
        "plt.ylabel('Topik', fontsize=12)\n",
        "plt.legend(title='Sentimen')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "IfrQ01oy4R0x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}